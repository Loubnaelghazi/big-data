{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde7b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import split, col\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "import subprocess\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "\n",
    "conf = SparkConf().setAppName('myapp')\n",
    "conf.set('spark.python.worker.timeout', '600')\n",
    "conf.set('spark.executor.memory', '4g')\n",
    "conf.set('spark.driver.memory', '4g')\n",
    "conf.set('spark.executor.cores', '2')\n",
    "conf.set('spark.python.worker.reuse', 'true')\n",
    "conf.set('spark.executor.heartbeatInterval', '200s')\n",
    "conf.set('spark.yarn.executor.memoryOverhead', '2048')\n",
    "conf.set('spark.network.timeout', '300s')\n",
    "\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "\n",
    "model_path = 'C:/Users/hanane/Desktop/Kafka/Model/pipeline_model/'\n",
    "\n",
    "try:\n",
    "    pipeline_model = PipelineModel.load(model_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model from {model_path}: {e}\")\n",
    "    raise\n",
    "\n",
    "def process_with_model(data):\n",
    "    try:\n",
    "        \n",
    "        row_data = Row(**data)\n",
    "        df = spark.createDataFrame([row_data])\n",
    "        prediction = pipeline_model.transform(df)\n",
    "        return prediction.collect()\n",
    "    except Exception as ex:\n",
    "        print(\"Model processing error: \", ex)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb207d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client.BigData\n",
    "collection = db.new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e21db8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received message: {'Tweet ID': 7925, 'Entity': 'MaddenNFL', 'Sentiment': 'Positive', 'Tweet content': 'Thank you @EAMaddenNFL!! \\n\\nNew TE Austin Hooper in the ORANGE & BROWN!! \\n\\n#Browns | @AustinHooper18 \\n\\n pic.twitter.com/GRg4xzFKOn'}\n",
      "Prediction: 1.0\n",
      "{'id': 7925, 'topic': 'MaddenNFL', 'content': 'Thank you @EAMaddenNFL!! \\n\\nNew TE Austin Hooper in the ORANGE & BROWN!! \\n\\n#Browns | @AustinHooper18 \\n\\n pic.twitter.com/GRg4xzFKOn', 'prediction': 1.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 11332, 'Entity': 'TomClancysRainbowSix', 'Sentiment': 'Positive', 'Tweet content': 'Rocket League, Sea of Thieves or Rainbow Six: SiegeðŸ¤”? I love playing all three on stream but which is the best? #stream #twitch #RocketLeague #SeaOfThieves #RainbowSixSiege #follow'}\n",
      "Prediction: 1.0\n",
      "{'id': 11332, 'topic': 'TomClancysRainbowSix', 'content': 'Rocket League, Sea of Thieves or Rainbow Six: SiegeðŸ¤”? I love playing all three on stream but which is the best? #stream #twitch #RocketLeague #SeaOfThieves #RainbowSixSiege #follow', 'prediction': 1.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 1107, 'Entity': 'AssassinsCreed', 'Sentiment': 'Positive', 'Tweet content': 'my ass still knee-deep in Assassins Creed Odyssey with no way out anytime soon lmao'}\n",
      "Prediction: 1.0\n",
      "{'id': 1107, 'topic': 'AssassinsCreed', 'content': 'my ass still knee-deep in Assassins Creed Odyssey with no way out anytime soon lmao', 'prediction': 1.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 2069, 'Entity': 'CallOfDuty', 'Sentiment': 'Negative', 'Tweet content': 'FIX IT JESUS ! Please FIX IT ! What In the world is going on here.  @PlayStation @AskPlayStation @Playstationsup @Treyarch @CallofDuty negative 345 silver wolf error code pic.twitter.com/ziRyhrf59Q'}\n",
      "Prediction: 0.0\n",
      "{'id': 2069, 'topic': 'CallOfDuty', 'content': 'FIX IT JESUS ! Please FIX IT ! What In the world is going on here.  @PlayStation @AskPlayStation @Playstationsup @Treyarch @CallofDuty negative 345 silver wolf error code pic.twitter.com/ziRyhrf59Q', 'prediction': 0.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 3185, 'Entity': 'Dota2', 'Sentiment': 'Positive', 'Tweet content': 'The professional dota 2 scene is fucking exploding and I completely welcome it.\\n\\nGet the garbage out.'}\n",
      "Prediction: 1.0\n",
      "{'id': 3185, 'topic': 'Dota2', 'content': 'The professional dota 2 scene is fucking exploding and I completely welcome it.\\n\\nGet the garbage out.', 'prediction': 1.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 1172, 'Entity': 'AssassinsCreed', 'Sentiment': 'Positive', 'Tweet content': 'Itching to assassinate \\n\\n#TCCGif #AssassinsCreedBlackFlag #AssassinsCreed #TheCapturedCollective pic.twitter.com/vv8MOGtCjw'}\n",
      "Prediction: 1.0\n",
      "{'id': 1172, 'topic': 'AssassinsCreed', 'content': 'Itching to assassinate \\n\\n#TCCGif #AssassinsCreedBlackFlag #AssassinsCreed #TheCapturedCollective pic.twitter.com/vv8MOGtCjw', 'prediction': 1.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 11783, 'Entity': 'Verizon', 'Sentiment': 'Negative', 'Tweet content': '@FredTJoseph hey fred, Comcast cut the cable and now Verizon stays calling me to shut that too pic.twitter.com/CPWSrmueDg'}\n",
      "Prediction: 0.0\n",
      "{'id': 11783, 'topic': 'Verizon', 'content': '@FredTJoseph hey fred, Comcast cut the cable and now Verizon stays calling me to shut that too pic.twitter.com/CPWSrmueDg', 'prediction': 0.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 4286, 'Entity': 'CS-GO', 'Sentiment': 'Neutral', 'Tweet content': 'CSGO WIngman (Im Silver dont bully) twitch.tv/lprezh'}\n",
      "Prediction: 2.0\n",
      "{'id': 4286, 'topic': 'CS-GO', 'content': 'CSGO WIngman (Im Silver dont bully) twitch.tv/lprezh', 'prediction': 2.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 8431, 'Entity': 'NBA2K', 'Sentiment': 'Negative', 'Tweet content': '@NBA2K game sucks... down by 2 with 38 seconds left and my team intentionally fouls'}\n",
      "Prediction: 0.0\n",
      "{'id': 8431, 'topic': 'NBA2K', 'content': '@NBA2K game sucks... down by 2 with 38 seconds left and my team intentionally fouls', 'prediction': 0.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 9135, 'Entity': 'Nvidia', 'Sentiment': 'Positive', 'Tweet content': 'Congrats to the NVIDIA NeMo team for the 1.0.0 release candidate!\\nReally excited to see NeMo embracing Hydra as the way to take control over the configuration madness that is machine learning! :)'}\n",
      "Prediction: 1.0\n",
      "{'id': 9135, 'topic': 'Nvidia', 'content': 'Congrats to the NVIDIA NeMo team for the 1.0.0 release candidate!\\nReally excited to see NeMo embracing Hydra as the way to take control over the configuration madness that is machine learning! :)', 'prediction': 1.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 4822, 'Entity': 'GrandTheftAuto(GTA)', 'Sentiment': 'Positive', 'Tweet content': 'yeah and itâ€™s fun'}\n",
      "Prediction: 1.0\n",
      "{'id': 4822, 'topic': 'GrandTheftAuto(GTA)', 'content': 'yeah and itâ€™s fun', 'prediction': 1.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 3068, 'Entity': 'Dota2', 'Sentiment': 'Negative', 'Tweet content': 'fuck my life ðŸ˜†'}\n",
      "Prediction: 0.0\n",
      "{'id': 3068, 'topic': 'Dota2', 'content': 'fuck my life ðŸ˜†', 'prediction': 0.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 10537, 'Entity': 'RedDeadRedemption(RDR)', 'Sentiment': 'Positive', 'Tweet content': 'happy birthday red dead redemption that shit changed my life what a crazy experience'}\n",
      "Prediction: 1.0\n",
      "{'id': 10537, 'topic': 'RedDeadRedemption(RDR)', 'content': 'happy birthday red dead redemption that shit changed my life what a crazy experience', 'prediction': 1.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 8056, 'Entity': 'Microsoft', 'Sentiment': 'Negative', 'Tweet content': 'What does that say about Microsoft hardware & software security - The Man gets hacked'}\n",
      "Prediction: 0.0\n",
      "{'id': 8056, 'topic': 'Microsoft', 'content': 'What does that say about Microsoft hardware & software security - The Man gets hacked', 'prediction': 0.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 2131, 'Entity': 'CallOfDuty', 'Sentiment': 'Negative', 'Tweet content': 'The new @CallofDuty for ps5 is ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥\\nOh God ðŸ˜­ðŸ˜'}\n",
      "Prediction: 0.0\n",
      "{'id': 2131, 'topic': 'CallOfDuty', 'content': 'The new @CallofDuty for ps5 is ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥\\nOh God ðŸ˜­ðŸ˜', 'prediction': 0.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 5450, 'Entity': 'Hearthstone', 'Sentiment': 'Neutral', 'Tweet content': 'Anyone that plays a bad luck albatross deck in hearthstone is a literal cop. \\n\\nFucking fun police. pic.twitter.com/jY6TRq351e'}\n",
      "Prediction: 2.0\n",
      "{'id': 5450, 'topic': 'Hearthstone', 'content': 'Anyone that plays a bad luck albatross deck in hearthstone is a literal cop. \\n\\nFucking fun police. pic.twitter.com/jY6TRq351e', 'prediction': 2.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 2286, 'Entity': 'CallOfDuty', 'Sentiment': 'Irrelevant', 'Tweet content': \"Call of duty warzone (livestream) w/ subs #Warzone youtu.be/7BhH_pjOMU4 via @YouTube Please come watch this AMAZING Call of Duty Warzone stream from this AMAZING streamer! It'd be really, really nice to give him some views and likes as well! ðŸ˜€ #COD #CallofDuty #Warzone\"}\n",
      "Prediction: 3.0\n",
      "{'id': 2286, 'topic': 'CallOfDuty', 'content': \"Call of duty warzone (livestream) w/ subs #Warzone youtu.be/7BhH_pjOMU4 via @YouTube Please come watch this AMAZING Call of Duty Warzone stream from this AMAZING streamer! It'd be really, really nice to give him some views and likes as well! ðŸ˜€ #COD #CallofDuty #Warzone\", 'prediction': 3.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 4038, 'Entity': 'CS-GO', 'Sentiment': 'Negative', 'Tweet content': 'Finally played Rainbow Six Siege for the first time... I have to admit, I prefer it over pulling my hair out in CSGO any day.'}\n",
      "Prediction: 0.0\n",
      "{'id': 4038, 'topic': 'CS-GO', 'content': 'Finally played Rainbow Six Siege for the first time... I have to admit, I prefer it over pulling my hair out in CSGO any day.', 'prediction': 0.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 526, 'Entity': 'ApexLegends', 'Sentiment': 'Neutral', 'Tweet content': 'Umm @PlayApex  when I died it said Bug This pic.twitter.com/bzMHzbadOF'}\n",
      "Prediction: 2.0\n",
      "{'id': 526, 'topic': 'ApexLegends', 'content': 'Umm @PlayApex  when I died it said Bug This pic.twitter.com/bzMHzbadOF', 'prediction': 2.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 8977, 'Entity': 'Nvidia', 'Sentiment': 'Neutral', 'Tweet content': '#gtc20 -  nice, motivational, and very accessible Nvidia/AI product fair + related tech talks\\nnvidia.com/en-us/gtc/keynâ€¦\\ninteresting interaction/social activities: braindates, dinner with strangers, ...  and free attendance for universities: reg.rainfocus.com/flow/nvidia/gtâ€¦'}\n",
      "Prediction: 1.0\n",
      "{'id': 8977, 'topic': 'Nvidia', 'content': '#gtc20 -  nice, motivational, and very accessible Nvidia/AI product fair + related tech talks\\nnvidia.com/en-us/gtc/keynâ€¦\\ninteresting interaction/social activities: braindates, dinner with strangers, ...  and free attendance for universities: reg.rainfocus.com/flow/nvidia/gtâ€¦', 'prediction': 1.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 11995, 'Entity': 'Verizon', 'Sentiment': 'Negative', 'Tweet content': \"Yo! @Verizon just added a $120 'fee' to my account under #COVID19 protection without my permission and I am forced to pay it! Check your bills carefully!\"}\n",
      "Prediction: 0.0\n",
      "{'id': 11995, 'topic': 'Verizon', 'content': \"Yo! @Verizon just added a $120 'fee' to my account under #COVID19 protection without my permission and I am forced to pay it! Check your bills carefully!\", 'prediction': 0.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 9449, 'Entity': 'Overwatch', 'Sentiment': 'Irrelevant', 'Tweet content': 'They might not be the last team that has to make this difficult decision. #update #overwatchleague #nyxl #overwatch #overwatch2 #blizzard #games #lockdown pic.twitter.com/dI1HTl4mcV'}\n",
      "Prediction: 3.0\n",
      "{'id': 9449, 'topic': 'Overwatch', 'content': 'They might not be the last team that has to make this difficult decision. #update #overwatchleague #nyxl #overwatch #overwatch2 #blizzard #games #lockdown pic.twitter.com/dI1HTl4mcV', 'prediction': 3.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 10193, 'Entity': 'PlayerUnknownsBattlegrounds(PUBG)', 'Sentiment': 'Irrelevant', 'Tweet content': 'Best squad yet#pubg #pubgmobile #pubgkenya instagram.com/p/B-Obt_eAA4f/â€¦'}\n",
      "Prediction: 3.0\n",
      "{'id': 10193, 'topic': 'PlayerUnknownsBattlegrounds(PUBG)', 'content': 'Best squad yet#pubg #pubgmobile #pubgkenya instagram.com/p/B-Obt_eAA4f/â€¦', 'prediction': 3.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 2419, 'Entity': 'Borderlands', 'Sentiment': 'Negative', 'Tweet content': \"@Borderlands how do I submit a complaint? Your CEO isn't paying his staff their bonuses.\"}\n",
      "Prediction: 0.0\n",
      "{'id': 2419, 'topic': 'Borderlands', 'content': \"@Borderlands how do I submit a complaint? Your CEO isn't paying his staff their bonuses.\", 'prediction': 0.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 8857, 'Entity': 'Nvidia', 'Sentiment': 'Positive', 'Tweet content': 'Watching NVIDIA position itself as not just a leading hardware manufacturer but also providing meaningful software to consumers is a remarkable thing of beauty. What an incredibly lead company with clear focus and goals. Well done @nvidia.'}\n",
      "Prediction: 1.0\n",
      "{'id': 8857, 'topic': 'Nvidia', 'content': 'Watching NVIDIA position itself as not just a leading hardware manufacturer but also providing meaningful software to consumers is a remarkable thing of beauty. What an incredibly lead company with clear focus and goals. Well done @nvidia.', 'prediction': 1.0}\n",
      "-------------------------\n",
      "Received message: {'Tweet ID': 9704, 'Entity': 'PlayStation5(PS5)', 'Sentiment': 'Positive', 'Tweet content': 'I donâ€™t see how this looks like as Xbox controller but yâ€™all will say anything. Anyway this is fire.'}\n",
      "Model processing error:  An error occurred while calling o4656.collectToPython.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 43.0 failed 1 times, most recent failure: Lost task 0.0 in stage 43.0 (TID 118) (DESKTOP-DKRJMDR executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\n",
      "\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\n",
      "\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\n",
      "\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\n",
      "\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\n",
      "\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\n",
      "\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409)\n",
      "\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\n",
      "\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\n",
      "\tat java.net.ServerSocket.accept(ServerSocket.java:513)\n",
      "\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\n",
      "\t... 32 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4148)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4145)\n",
      "\tat sun.reflect.GeneratedMethodAccessor133.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Python worker failed to connect back.\n",
      "\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\n",
      "\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\n",
      "\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\n",
      "\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\n",
      "\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\n",
      "\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409)\n",
      "\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\n",
      "\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\n",
      "\tat java.net.ServerSocket.accept(ServerSocket.java:513)\n",
      "\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\n",
      "\t... 32 more\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m other_fields \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m message_value\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m     10\u001b[0m prediction \u001b[38;5;241m=\u001b[39m process_with_model(other_fields)\n\u001b[1;32m---> 11\u001b[0m per \u001b[38;5;241m=\u001b[39m prediction[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m per \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction:\u001b[39m\u001b[38;5;124m\"\u001b[39m, per)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "consumer = KafkaConsumer('twitter_data', bootstrap_servers='localhost:9092', group_id='1', value_deserializer=lambda x: json.loads(x.decode('utf-8')))\n",
    "try:\n",
    "    for message in consumer:\n",
    "        message_value = message.value\n",
    "        print(\"Received message:\", message_value)\n",
    "\n",
    "        other_fields = {key: value for key, value in message_value.items() if key != 'Sentiment'}\n",
    "        \n",
    "        \n",
    "        prediction = process_with_model(other_fields)\n",
    "        per = prediction[0]['prediction']\n",
    "        if per is not None:\n",
    "                print(\"Prediction:\", per)\n",
    "           \n",
    "        tweet_doc = {\n",
    "        \"id\": message_value.get('Tweet ID'),\n",
    "        \"topic\": message_value.get('Entity'),\n",
    "        \"content\": message_value.get('Tweet content'),\n",
    "        \"prediction\": per\n",
    "            }\n",
    "        print(tweet_doc)\n",
    "        print(\"-------------------------\")\n",
    "        collection.insert_one(tweet_doc)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d89e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2158a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6d018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
