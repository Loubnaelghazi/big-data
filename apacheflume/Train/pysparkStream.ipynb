{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589c1841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|      \"File \\u001...|\n",
      "|      \"File \\u001...|\n",
      "|      \"File \\u001...|\n",
      "|      \"File \\u001...|\n",
      "|      \"traceback\": [|\n",
      "|      \"\\u001b[1;3...|\n",
      "|      \"\\u001b[1;3...|\n",
      "|      \"Cell \\u001...|\n",
      "|      \"File \\u001...|\n",
      "|      \"Cell \\u001...|\n",
      "|      \"File \\u001...|\n",
      "|10951,TomClancysG...|\n",
      "|10951,TomClancysG...|\n",
      "|10951,TomClancysG...|\n",
      "|10952,TomClancysG...|\n",
      "|10952,TomClancysG...|\n",
      "|10952,TomClancysG...|\n",
      "|3333,Facebook,Irr...|\n",
      "|3334,Facebook,Irr...|\n",
      "|3334,Facebook,Irr...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read from HDFS\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data = spark.read.text(\"hdfs://localhost:9000/user/Hadoop/twit2/*\")\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c817cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|10951,TomClancysG...|\n",
      "|10951,TomClancysG...|\n",
      "|10951,TomClancysG...|\n",
      "|10952,TomClancysG...|\n",
      "|10952,TomClancysG...|\n",
      "|10952,TomClancysG...|\n",
      "|3333,Facebook,Irr...|\n",
      "|3334,Facebook,Irr...|\n",
      "|3334,Facebook,Irr...|\n",
      "|3334,Facebook,Irr...|\n",
      "|3334,Facebook,Irr...|\n",
      "|3334,Facebook,Irr...|\n",
      "|3334,Facebook,Irr...|\n",
      "|3335,Facebook,Irr...|\n",
      "|3335,Facebook,Irr...|\n",
      "|3335,Facebook,Irr...|\n",
      "|286,Amazon,Neutra...|\n",
      "|286,Amazon,Neutra...|\n",
      "|286,Amazon,Neutra...|\n",
      "|286,Amazon,Neutra...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "filtered_data = data.filter(~data[\"value\"].startswith('   ') )\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222968a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "split_col = split(filtered_data['value'], ',')\n",
    "\n",
    "filtered_data = filtered_data.withColumn('id', split_col.getItem(0)) \\\n",
    "                             .withColumn('topic', split_col.getItem(1)) \\\n",
    "                             .withColumn('sentiment', split_col.getItem(2)) \\\n",
    "                             .withColumn('content', split_col.getItem(3))\n",
    "\n",
    "filtered_data = filtered_data.drop('value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd3f15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+--------------------+\n",
      "|   id|               topic| sentiment|             content|\n",
      "+-----+--------------------+----------+--------------------+\n",
      "|10951|TomClancysGhostRecon|  Negative|@AskPS_UK  @Ubiso...|\n",
      "|10951|TomClancysGhostRecon|  Negative|@AskPS_UK 3 @Ubis...|\n",
      "|10951|TomClancysGhostRecon|  Negative|@AskPS_UK @Ubisof...|\n",
      "|10952|TomClancysGhostRecon|   Neutral|The Terminator ev...|\n",
      "|10952|TomClancysGhostRecon|   Neutral|The Terminator ev...|\n",
      "|10952|TomClancysGhostRecon|   Neutral|\"The event dedica...|\n",
      "| 3333|            Facebook|Irrelevant|Creepy geek not o...|\n",
      "| 3334|            Facebook|Irrelevant|Halloween died th...|\n",
      "| 3334|            Facebook|Irrelevant|\"Halloween died t...|\n",
      "| 3334|            Facebook|Irrelevant|\"Halloween died t...|\n",
      "| 3334|            Facebook|Irrelevant|Halloween died th...|\n",
      "| 3334|            Facebook|Irrelevant|Halloween died th...|\n",
      "| 3334|            Facebook|Irrelevant|Halloween died th...|\n",
      "| 3335|            Facebook|Irrelevant|               The  |\n",
      "| 3335|            Facebook|Irrelevant|                    |\n",
      "| 3335|            Facebook|Irrelevant|              \"Italy|\n",
      "|  286|              Amazon|   Neutral|amazon.in / Shiva...|\n",
      "|  286|              Amazon|   Neutral|amazon.in/Shivaji...|\n",
      "|  286|              Amazon|   Neutral|Mon amazon. in / ...|\n",
      "|  286|              Amazon|   Neutral|amazon.in/Shivaji...|\n",
      "+-----+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a72c1",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1c83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, StringIndexer, NGram\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes, LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805106d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filtered_data.na.drop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39f5268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the 'content' column\n",
    "tokenizer = Tokenizer().setInputCol('content').setOutputCol('words')\n",
    "\n",
    "# Remove stopwords\n",
    "stopwords = StopWordsRemover().getStopWords() + ['-']\n",
    "remover = StopWordsRemover().setStopWords(stopwords).setInputCol('words').setOutputCol('filtered')\n",
    "\n",
    "# Create bigrams\n",
    "bigram = NGram().setN(2).setInputCol('filtered').setOutputCol('bigrams')\n",
    "\n",
    "# Generate features using CountVectorizer\n",
    "cvmodel = CountVectorizer().setInputCol('filtered').setOutputCol('features')\n",
    "cvmodel_ngram = CountVectorizer().setInputCol('bigrams').setOutputCol('features')\n",
    "\n",
    "# Convert 'sentiment' column to a binary label\n",
    "indexer = StringIndexer().setInputCol('sentiment').setOutputCol('label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191d4719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|   id|               topic|sentiment|             content|               words|            filtered|             bigrams|            features|label|\n",
      "+-----+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|10951|TomClancysGhostRecon| Negative|@AskPS_UK  @Ubiso...|[@askps_uk, , @ub...|[@askps_uk, , @ub...|[@askps_uk ,  @ub...|(57034,[3,66,168,...|  0.0|\n",
      "|10951|TomClancysGhostRecon| Negative|@AskPS_UK 3 @Ubis...|[@askps_uk, 3, @u...|[@askps_uk, 3, @u...|[@askps_uk 3, 3 @...|(57034,[29,66,110...|  0.0|\n",
      "|10951|TomClancysGhostRecon| Negative|@AskPS_UK @Ubisof...|[@askps_uk, @ubis...|[@askps_uk, @ubis...|[@askps_uk @ubiso...|(57034,[66,168,63...|  0.0|\n",
      "|10952|TomClancysGhostRecon|  Neutral|The Terminator ev...|[the, terminator,...| [terminator, event]|  [terminator event]|(57034,[377,2274]...|  2.0|\n",
      "|10952|TomClancysGhostRecon|  Neutral|The Terminator ev...|[the, terminator,...| [terminator, event]|  [terminator event]|(57034,[377,2274]...|  2.0|\n",
      "+-----+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Define the pipeline stages\n",
    "pipeline_preprocess = Pipeline(stages=[tokenizer, remover, bigram, cvmodel, indexer])\n",
    "\n",
    "# Fit the pipeline to your data DataFrame\n",
    "preprocessed_model = pipeline_preprocess.fit(filtered_data)\n",
    "\n",
    "# Transform the data DataFrame\n",
    "preprocessed_data = preprocessed_model.transform(filtered_data)\n",
    "\n",
    "# Show the first 5 rows of the preprocessed DataFrame\n",
    "preprocessed_data.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45c808",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aceecf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData, testData  = filtered_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10f201cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|id   |topic                            |sentiment |content                                                                                                                                                                                                                                                                                                                                              |prediction|\n",
      "+-----+---------------------------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|10111|PlayerUnknownsBattlegrounds(PUBG)|Irrelevant|@PUBGMOBILE ( my game id 5176547049 and mine ORCpreda ) I was logged to my pubg account from a lap top in a cafe. I dont know know quite what happened suddenly my account number was banned for 10 year. Then I spend lot of my spending money to it. i played at this game since 2008 season band 3. please help convince me to get my account back|0.0       |\n",
      "|10303|PlayerUnknownsBattlegrounds(PUBG)|Irrelevant|1 Turbo Tuesday!!! |                                                                                                                                                                                                                                                                                                                                 |3.0       |\n",
      "|10303|PlayerUnknownsBattlegrounds(PUBG)|Irrelevant|Happy Turbo Hits Tuesday!!! |                                                                                                                                                                                                                                                                                                                        |1.0       |\n",
      "|10304|PlayerUnknownsBattlegrounds(PUBG)|Negative  |Problems:. -Rampant Sexual assualt in educational institutes.. -PIA Fake licenses.. -Baloch students arrested for protesting against inaccessibility of internet.. -215K corona cases & rising. -Christian man shot dead for buying house in Muslim majority.. Steps Taken:. -Ban PUBG                                                               |0.0       |\n",
      "|10569|RedDeadRedemption(RDR)           |Neutral   |More Poison Poppy moonshine And Recipe to searching                                                                                                                                                                                                                                                                                                  |2.0       |\n",
      "+-----+---------------------------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "pipeline_nb = Pipeline(stages=[tokenizer, remover, cvmodel, indexer, nb])\n",
    "model_nb = pipeline_nb.fit(trainingData)\n",
    "predictions_nb = model_nb.transform(testData)\n",
    "\n",
    "predictions_nb.select('id', 'topic', 'sentiment', 'content', 'prediction').show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f599d044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7375061299095003\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions_nb)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c0e77a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb.write().overwrite().save('C:/Users/hanane/Desktop/BigDataProje/apacheflume/ModelSave/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "226b486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3017811930884378\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression().setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "pipeline = Pipeline(stages = [tokenizer, remover, cvmodel, indexer, log_reg])\n",
    "model = pipeline.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "AUC = evaluator.evaluate(predictions)\n",
    "print(AUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2371108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33940389996890685\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import  RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier().setLabelCol('label').setFeaturesCol('features').setNumTrees(10)\n",
    "pipeline = Pipeline(stages = [tokenizer, remover, cvmodel, indexer, rf])\n",
    "model = pipeline.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "AUC = evaluator.evaluate(predictions)\n",
    "print(AUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd997cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
